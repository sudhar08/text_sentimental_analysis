{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudhar08/text_sentimental_analysis/blob/main/Extarct_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSjdioMpwFhc",
        "outputId": "1395942c-0792-493d-ce8e-231135a3e5ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.4.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.14.0 textstat-0.7.3\n"
          ]
        }
      ],
      "source": [
        "!pip install bs4\n",
        "!pip install  requests\n",
        "!pip install textstat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTCrotg2woRA",
        "outputId": "f1879eb5-42b1-4df6-a79b-44ad6bd41fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "7\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "20\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "107\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n",
            "a\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "datas = pd.read_csv(\"/content/Input.csv\")\n",
        "rows,col = datas.shape\n",
        "count = 0\n",
        "missed_one = []\n",
        "\n",
        "\n",
        "for i in range(rows):\n",
        "  url = requests.get(datas.URL[i])\n",
        "  soup = BeautifulSoup(url.text, \"html.parser\")\n",
        "  try:\n",
        "    title = soup.find('h1')\n",
        "    parent = soup.find(\"div\",class_ = \"tdb-block-inner td-fix-index\").find_all_next('p')\n",
        "    f = open(f'/content/text_files/{data.URL_ID[i]}.txt',\"a\")\n",
        "    print(f.mode)\n",
        "    f.write(title.text)\n",
        "    f.write(\"\\n\")\n",
        "    for p in parent:\n",
        "      f.write(p.text)\n",
        "      f.write(\"\\n\")\n",
        "    f.close()\n",
        "\n",
        "\n",
        "  except :\n",
        "    print(i)\n",
        "    missed_one.append(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0iPNnkIL4pE"
      },
      "source": [
        "THIS LINK ARE SHOW PAGE NO FOUND(404)\n",
        "https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
        "https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
        "https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDVYJSRqMENq",
        "outputId": "c03f08d0-e3c8-48b5-d027-ddb5e413cf02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGnGD25qmRDj",
        "outputId": "b517ee64-fc18-4821-ac4a-e82a4dede36f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p25riTDNp6af",
        "outputId": "5c933409-f161-4f92-92ee-b7ad51e5fcf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StopWords_Currencies.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "directory_files = os.listdir(\"/content/stopwords/\")\n",
        "try:\n",
        "  for files in directory_files:\n",
        "    read_files = open(f'/content/stopwords/{files}','r').read()\n",
        "    write_new_file = open(\"all stop word.txt\",'a')\n",
        "    write_new_file.write(read_files)\n",
        "    write_new_file.close()\n",
        "except:\n",
        "  print(files)\n",
        "  #break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9iVN3GbmerB"
      },
      "outputs": [],
      "source": [
        "from numpy import average\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import textstat\n",
        "import regex as re\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def find_complex_words(text):\n",
        "  complex_words = []\n",
        "  for word in text.split():\n",
        "    syllable_count = textstat.syllable_count(word)\n",
        "    if syllable_count >= 2:\n",
        "      complex_words.append(word)\n",
        "  return len( complex_words)\n",
        "\n",
        "\n",
        "def count_sentences(text):\n",
        "  sentences = 0\n",
        "  for i in range(len(text)):\n",
        "    if text[i] == \".\":\n",
        "      sentences += 1\n",
        "  return sentences\n",
        "\n",
        "def average_words_per_sentence(text):\n",
        "  total_words = len(text.split())\n",
        "  number_of_sentences = text.count(\".\")\n",
        "  average_words_per_sentence = total_words / number_of_sentences\n",
        "  return average_words_per_sentence\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def syllable_counts(word):\n",
        "  return textstat.syllable_count(word)\n",
        "\n",
        "def find_personal_pronouns(text):\n",
        "  personal_pronouns = []\n",
        "  pattern = r\"/(I|me|you|he|she|it|we|us|they|them)/\"\n",
        "  for match in re.finditer(pattern, text):\n",
        "    personal_pronouns.append(match.group(0))\n",
        "  return personal_pronouns\n",
        "\n",
        "def average_word_length(text):\n",
        "  words = text.split()\n",
        "  total_length = 0\n",
        "  for word in words:\n",
        "    total_length += len(word)\n",
        "  average_word_length = total_length / len(words)\n",
        "  return average_word_length\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def text_analysis(files):\n",
        "\n",
        "  own_stopwords = open(\"all_stop_word.txt\",'r',encoding=\"ISO-8859-1\").read().lower()\n",
        "\n",
        "  text = open(f\"/content/text_files/{files}\",'r').read().lower()\n",
        "\n",
        "  positive = open(\"/content/positive-words.txt\",'r',encoding=\"ISO-8859-1\").read().lower()\n",
        "  negative = open(\"/content/negative-words.txt\",'r',encoding=\"ISO-8859-1\").read().lower()\n",
        "\n",
        "  pos = 0\n",
        "  neg = 0\n",
        "  total_number_of_words = text.split()\n",
        "  number_of_sentence = count_sentences(text)\n",
        "\n",
        "  average_sent = len(total_number_of_words)/number_of_sentence\n",
        "  complex_words_percentage = (find_complex_words(text)/len(total_number_of_words))*100\n",
        "\n",
        "  Fog_Index =  0.4*(average_sent + complex_words_percentage)\n",
        "  AverageNumberofWordsPerSentence =  average_words_per_sentence(text)\n",
        "\n",
        "  complex_word_count = find_complex_words(text)\n",
        "\n",
        "  word_count = text.split()\n",
        "  PERSONALPRONOUNS = find_personal_pronouns(text)\n",
        "  AVGWORDLENGTH = average_word_length(text)\n",
        "\n",
        "  data = text\n",
        "  stopWords = stopwords.words('english')\n",
        "  stopWords.extend(own_stopwords)\n",
        "  words = word_tokenize(data)\n",
        "\n",
        "  wordsFiltered = []\n",
        "  length  = len(text)\n",
        "\n",
        "  for w in words:\n",
        "      if w not in stopWords:\n",
        "          wordsFiltered.append(w)\n",
        "  for word in wordsFiltered:\n",
        "    if word in positive:\n",
        "      pos+=1\n",
        "    elif word in negative:\n",
        "      neg-=1\n",
        "    else:\n",
        "      pass\n",
        "  SYLLABLEPERWORD = syllable_counts(wordsFiltered[0])\n",
        "  positive_score = ((pos/len(wordsFiltered)))\n",
        "  negative_score = ((neg/len(wordsFiltered)))\n",
        "  pollarity_score = (positive_score - negative_score)/((positive_score + negative_score)+0.000001)\n",
        "  Subjectivity_Score = (positive_score + negative_score)/(len(wordsFiltered)+0.000001)\n",
        "\n",
        "  return positive_score,negative_score,pollarity_score,Subjectivity_Score,average_sent,complex_words_percentage,Fog_Index,AverageNumberofWordsPerSentence,complex_word_count,SYLLABLEPERWORD, PERSONALPRONOUNS,AVGWORDLENGTH\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "oZcH-qn9zjzV",
        "outputId": "3f1880f5-b2d7-4b07-b444-2ef5ad8c8536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109\n",
            "56\n",
            "120\n",
            "128\n",
            "145\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-198-8ac7cd343cb5>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"URL_ID\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-179-ef0672ee9b20>\u001b[0m in \u001b[0;36mtext_analysis\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopWords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m           \u001b[0mwordsFiltered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwordsFiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from pandas.io.formats.style_render import Index\n",
        "import os\n",
        "from openpyxl import Workbook\n",
        "\n",
        "directory_files = os.listdir(\"/content/text_files/\")\n",
        "\n",
        "\n",
        "\n",
        "for files in directory_files:\n",
        "  id = files.split(\".\")[0]\n",
        "  print(id)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  try:\n",
        "\n",
        "\n",
        "    analysis = text_analysis(files)\n",
        "\n",
        "    break\n",
        "\n",
        "  except Exception as e:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmMTtf9NL8Jw"
      },
      "source": [
        "!zip -r /content/text_files /content/text_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEstpMi8qkpv",
        "outputId": "28a8f83e-6276-4c57-c332-26925b856855"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "URL_ID                                                                            109\n",
              "URL                                 https://insights.blackcoffer.com/lessons-from-...\n",
              "POSITIVE SCORE                                                                    NaN\n",
              "NEGATIVE SCORE                                                                    NaN\n",
              "POLARITY SCORE                                                                    NaN\n",
              "SUBJECTIVITY SCORE                                                                NaN\n",
              "AVG SENTENCE LENGTH                                                               NaN\n",
              "PERCENTAGE OF COMPLEX WORDS                                                       NaN\n",
              "FOG INDEX                                                                         NaN\n",
              "AVG NUMBER OF WORDS PER SENTENCE                                                  NaN\n",
              "COMPLEX WORD COUNT                                                                NaN\n",
              "WORD COUNT                                                                        NaN\n",
              "SYLLABLE PER WORD                                                                 NaN\n",
              "PERSONAL PRONOUNS                                                                 NaN\n",
              "AVG WORD LENGTH                                                                   NaN\n",
              "Name: 109, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ],
      "source": [
        "output.loc[109]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "DII_a2l8otkY",
        "outputId": "56169b01-5764-4d6f-ec51-0e27d3747b9a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f2a8ca90-bed8-43b8-9d2e-6dce6bcf4c62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL_ID</th>\n",
              "      <th>URL</th>\n",
              "      <th>POSITIVE SCORE</th>\n",
              "      <th>NEGATIVE SCORE</th>\n",
              "      <th>POLARITY SCORE</th>\n",
              "      <th>SUBJECTIVITY SCORE</th>\n",
              "      <th>AVG SENTENCE LENGTH</th>\n",
              "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
              "      <th>FOG INDEX</th>\n",
              "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
              "      <th>COMPLEX WORD COUNT</th>\n",
              "      <th>WORD COUNT</th>\n",
              "      <th>SYLLABLE PER WORD</th>\n",
              "      <th>PERSONAL PRONOUNS</th>\n",
              "      <th>AVG WORD LENGTH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2a8ca90-bed8-43b8-9d2e-6dce6bcf4c62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2a8ca90-bed8-43b8-9d2e-6dce6bcf4c62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2a8ca90-bed8-43b8-9d2e-6dce6bcf4c62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [URL_ID, URL, POSITIVE SCORE, NEGATIVE SCORE, POLARITY SCORE, SUBJECTIVITY SCORE, AVG SENTENCE LENGTH, PERCENTAGE OF COMPLEX WORDS, FOG INDEX, AVG NUMBER OF WORDS PER SENTENCE, COMPLEX WORD COUNT, WORD COUNT, SYLLABLE PER WORD, PERSONAL PRONOUNS, AVG WORD LENGTH]\n",
              "Index: []"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(columns=[\"URL_ID\",\"URL\",\"POSITIVE SCORE\",\t\"NEGATIVE SCORE\",\"POLARITY SCORE\",\t\"SUBJECTIVITY SCORE\",\t\"AVG SENTENCE LENGTH\",\t\"PERCENTAGE OF COMPLEX WORDS\",\t\"FOG INDEX\",\t\"AVG NUMBER OF WORDS PER SENTENCE\",\t\"COMPLEX WORD COUNT\",\t\"WORD COUNT\",\t\"SYLLABLE PER WORD\",\t\"PERSONAL PRONOUNS\",\t\"AVG WORD LENGTH\"])\n",
        "df.append(datas.URL_ID[])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPX6G9AuBQbZ7r2Qng17le",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}